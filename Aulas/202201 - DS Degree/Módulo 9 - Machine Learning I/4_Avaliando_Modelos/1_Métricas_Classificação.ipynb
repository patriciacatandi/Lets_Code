{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Métricas de avaliação\n",
    "Como podemos mensurar a qualidade do modelo? Ou, se treinarmos vários modelos diferentes, como determinar qual é o melhor?\n",
    "\n",
    "Para responder a estas perguntas, utilizamos as **métricas de avaliação** de modelos de classificação.\n",
    "\n",
    "Em um problema de classificação binária podemos ter as seguintes denominações:\n",
    "<br>\n",
    "* TP representa a quantidade de True Positive (Verdadeiro Positivo): classes 1 que foram previstas como 1\n",
    "* TN representa a quantidade de True Negative (Verdadeiro Negativo): classes 0 que foram previstas como 0\n",
    "* FP representa a quantidade de False Positive (Falso Positivo): classes 0 que foram previstas como 1\n",
    "* FN representa a quantidade de False Negative (Falso Negativo): classes 1 que foram previstas como 0\n",
    "\n",
    "<img src=\"images/compare.png\" />\n",
    "\n",
    "Existem diversas formas de realizar tais avaliações, cada uma observando o problema de um ponto de vista diferente.\n",
    "\n",
    "\n",
    "### 2.1 Acurácia\n",
    "*No geral, com que frequência o classificador acerta?* <br> <br>\n",
    "Também conhecida como **taxa de acerto**, essa medida de desempenho traz a proporção de acertos sobre o total de observações:\n",
    "\n",
    "$$\n",
    "\\frac{VP + VN}{VP + VN + FP + FN}\n",
    "$$ \n",
    "\n",
    "\n",
    "A taxa de acerto é um número *limitado entre 0 e 1*. Quanto *maior for o seu valor, mais acurado é o modelo M*.\n",
    "\n",
    "**Problema da acurácia (Null acurracy)** <br>\n",
    "Esse problema ocorre quando temos classes desbalanceadas. <br>\n",
    "\n",
    "Exemplo: Suponha um problema de classificação binária no qual 130 amostras são da classe 0 e 62 são da classe 1, ou seja, 67.7% dos nossos dados pertencem à classe 0.  <br> \n",
    "Isso significa que um modelo dumb que sempre desse 0 como resposta, estaria certo em 68% dos casos. <br>\n",
    "É importante sabermos esse valor para utilizar como baseline dos nossos modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Matriz de Confusão\n",
    "Uma alternativa para visualizar o desempenho de um modelo é analisar sua matriz de confusão, que ilustra o número de predições corretas e incorretas para cada classe do modelo.\n",
    "\n",
    "* As linhas dessa matriz representam as classes verdadeiras;\n",
    "\n",
    "* As colunas representam as classes preditas pelo modelo.\n",
    "\n",
    "Logo, cada elemento $ m_{ij} $ de uma matriz de confusão M apresenta o número de exemplos da classe **i** classificados como classe **j**.\n",
    "\n",
    "Dessa forma, os elementos na **diagonal principal** indicam as classificações feitas de forma **correta**, enquanto os **outros elementos** são os classificados de forma **incorreta**.\n",
    "\n",
    "<img src=\"images/matriz_confusao_explicada.svg\"  style=\"width:600px\" />\n",
    "\n",
    "Por meio dela, temos as medidas quantitativas de quais classes possuem maior dificuldade de serem corretamente classificadas, se existe alguma \"confusão\" recorrente entre duas classes e mais uma série de medidas quantitativas sobre o modelo, como veremos a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 68.5%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importar accuracy_score e plot_confusion_matrix do sklearn.metrics \n",
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "\n",
    "# Calcular a acurácia utilizando o accuracy_score\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Acurácia do modelo: {ac:.1%}\")\n",
    "\n",
    "plot_confusion_matrix(clf, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/metricas_classificacao.svg\"  style=\"width:600px\" />\n",
    "\n",
    "### 2.3 Precision\n",
    "*When a positive value is predicted, how often is the prediction correct? How \"precise\" is the classifier when predicting positive instances?*\n",
    "\n",
    "> Definição: Precisão mede quantas amostras preditas como positivas eram de fato positivas\n",
    "     \n",
    "$$ Precision = \\frac{TP}{TP+FP}  $$\n",
    "\n",
    "O Precision varia entre 0 e 1.\n",
    "\n",
    "Quando utilizar:\n",
    "- você precisa restringir o número de FP\n",
    "- não há preocupação com os FN (já que eles são ignorados)\n",
    "- você quer ter certeza de que quando o modelo prediz um positivo ele de fato é positivo\n",
    "\n",
    "Exemplo: <br>\n",
    "- Uma indústria farmaceutica criou um novo teste de gravidez e quer que seu teste identifique corretamente quando a pessoa está grávida. Não há tanta preocupação com os FN pois em algum outro momento a gravidez será descoberta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Recall / Sensitividade / True Positive Rate (TPR) <br>\n",
    "*Quão sensível é o classificador em prever instâncias positivas?* <br>\n",
    "*Dos valores preditos como positivos, quantos estavam de fato corretos?* <br>\n",
    "\n",
    "> Definição: De todos os casos positivos, quantos conseguimos identificar?\n",
    "\n",
    " O Recall varia entre 0 e 1.\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "Quando utilizar: \n",
    "- você precisa restringir o número de FN\n",
    "- não há preocupação com os FP (já que eles são ignorados na fórmula)\n",
    "- você quer obter o maior número de valores positivos\n",
    "\n",
    "Exemplo:\n",
    "- Uma empresa farmaceutica que produz teste de detecção de câncer decide por usar o Recall a fim de reduzir os FN o máximo possível.\n",
    "\n",
    "\n",
    "### 2.5 Matriz de Confusão não binária\n",
    "<img src=\"images/matriz_3x3.svg\"  style=\"width:600px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual métrica devo escolher?\n",
    "\n",
    "    Choice of metric depends on your business objective\n",
    "        Identify if FP or FN is more important to reduce\n",
    "        Choose metric with relevant variable (FP or FN in the equation)\n",
    "    Spam filter (positive class is \"spam\"):\n",
    "        Optimize for precision or specificity\n",
    "            precision\n",
    "                false positive as variable\n",
    "            specificity\n",
    "                false positive as variable\n",
    "        Because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
    "    Fraudulent transaction detector (positive class is \"fraud\"):\n",
    "        Optimize for sensitivity\n",
    "            FN as a variable\n",
    "        Because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Tradeoff\n",
    "Em geral, maximizar a precisão gera uma redução no valor de recall e vice-versa. Como resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 - Score\n",
    "É uma média harmônica entre Precision e Recall que penaliza quando um dos dois (ou ambos) é muito baixo (devido à multiplicação desses scores no numerador). O F1 varia entre 0 e 1.\n",
    "\n",
    "$$F1 = \\frac{2* Recall * Precision}{Recall + Precision}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Especificidade / True Negative Rate (TNR)\n",
    "*Quão sensível é o classificador em prever instâncias negativas?* <br>\n",
    "*Dos valores preditos como negativos, quantos estavam de fato corretos?* <br>\n",
    "$$specificity = \\frac{TN}{TN + FP} = 1-FPR$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.4. Curva ROC\n",
    "Uma forma alternativa e comum de avaliar classificadores em problemas binários é por meio do uso das curvas ROC (Receiving Operating Characteristics).\n",
    "\n",
    "Seu gráfico é bidimensional: <br>\n",
    "        * eixo y -  True Positive Rate (TPR) = Recall <br>\n",
    "        * eixo x -  False Positive Rate (FPR) = (1 - Specificity) <br>\n",
    "\n",
    "Para um modelo genérico a curva ROC é parecida com a da figura a seguir:\n",
    "\n",
    "<img src=\"images/ROCAUC.png\"  style=\"width: 500px\" />\n",
    "\n",
    "Em resumo, a curva representa a relação entre a TPR e a FPR e quanto maior a **área abaixo da curva (AUC - Area Under Curve)** melhor é o modelo.\n",
    "<br>\n",
    "Para plotar essa curva nós precisamos setar diferentes valores de threshold que definem a qual classe pertence cada amostra e calcular qual o valor de TPR e FPR para esse threshold. Considere um problema de duas classes cada um com 100 amostras cujo gráfico de probabilidades se encontra abaixo. Selecionamos 7 thresholds distintos que irão definir à qual classe percence aquela amostra cujos valores estão exemplificados nas figuras.\n",
    "\n",
    "<img src=\"images/prob example.png\"  style=\"width: 1000px\" />\n",
    "\n",
    "\n",
    "| Threshold |                     Descrição                      | TPR = tp/tp+fn  | FPR = 1 - tn/fp+tn | \n",
    "|-----------|----------------------------------------------------|-----------------|-------------------|\n",
    "|     0     | Todas as amostras são classificadas como Positivas | 100/(100+0) = 1 | 1 - 0/(100+0) = 1 |\n",
    "|    100    | Todas as amostras são classificadas como Negativas | 0/(0+100) = 0   | 1 - 100/(0+100) = 0 |\n",
    "\n",
    "Idealmente queremos reduzir a quantidade de amostras classificadas incorretamente (FP e FN) e ao mesmo tempo tentar deixar a curva o mais próximo de TPR=1 e FPR=0 até que todas as amostras TP tenham sido classificadas. Dependendo da curva obtida com o modelo podemos classificá-lo de acordo com sua performance.\n",
    "\n",
    "<img src=\"images/ROCAUC2.png\"  style=\"width: 500px\" />\n",
    "\n",
    "Se um modelo se encontra na diagonal, dizemos que ele possui comportamento similar ao lançamento de uma moeda não viciada e temos um modelo aleatório.\n",
    "\n",
    "*Modelos abaixo dessa linha são piores que o aleatório, enquanto que acima são modelos melhores que o aleatório.*\n",
    "\n",
    "* Se um modelo está na **ponta superior esquerda** (chamada de céu ROC), dizemos que é um **modelo perfeito**;\n",
    "* Se está na **ponta superior direita ou inferior esqueda**, o modelo sempre classificará novos itens como positivos ou negativos, respectivamente;\n",
    "* Se está na **ponta inferior direita** (chamada de inferno ROC), esse modelo estará **sempre errando**.\n",
    "\n",
    "\n",
    "<img src=\"images/1341805045.jpg\" text=\"Fonte: www.datasciencecentral.com/roc-curve-explained-in-one-picture\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Comparando modelos distintos\n",
    "Com essa métrica também conseguimos comparar modelos distintos sendo o melhor deles aquele que se aproxima de TPR=1:\n",
    "\n",
    "<img src=\"images/compare_models.png\"  style=\"width: 500px\" />\n",
    "\n",
    "*Quando não há interseções entre as curvas de dois modelos, significa que o modelo que possui sua curva mais próxima do céu ROC é o que oferece melhor desempenho.*\n",
    "\n",
    "Ao existir cruzamentos, cada um terá um desempenho melhor que o outro de acordo com a região.\n",
    "\n",
    "## AUC-ROC (Area Under the ROC Curve)\n",
    "\n",
    "Entretanto, o mais comum é a determinação da **área abaixo da curva ROC (AUC-ROC)** para cada modelo e compará-los com essa medida única, que é compreendida entre 0 e 1:\n",
    "\n",
    "* Valores próximos de 1 são considerados os melhores;\n",
    "* Valores próximos a 0,5 são considerados aleatórios.\n",
    "<br>\n",
    "A AUC-ROC trás duas grandes vantagens:\n",
    "\n",
    "* Mede a qualidade da predição do modelo independente do threshold;\n",
    "* Robustez contra o desbalanceamento.\n",
    "\n",
    "Modelos com maior AUC conseguem discriminar melhor entre as classes.\n",
    "\n",
    "ROC AUC also tends to be dominated by the \"high FPR\" points. Depending on the application, these points may be the least relevant. Consider the case where the model is used to refer high-risk transactions to experts who will conduct further vetting. There may only be enough humans to assess 50 transactions per unit time; since the most highly-ranked transactions occur on the \"left hand\" size of the ROC curve by definition, this is also the region with the lowest area. So by looking at the whole AUC, you're optimistically biasing your results upwards, i.e. ROC AUC is buoyed by the observations \"to the right\" of the actual set of observations which humans will vet. (Illustration is simple. Draw a vertical line at FPR<0.5 on any ROC curve. The area to left is higher for all such vertical lines.) To avoid this, some people use partial ROC AUC, which has its own host of problems, chief among them that software implementations tend to assume that you're interested in truncation at some value of FPR. But in the case that you care about the top n transactions, this approach is obviously wrong because the top n transactions will happen at different FPR values for different classifiers. Standardization of partial AUC (to preserve the property that AUC < 0.5 is worse than random, 1 is perfect, 0 is worthless) incurs further difficulties.\n",
    "\n",
    "A AUC deve ser utilizada em classificações binárias. Para multi-classes podemos usar o one-to-rest AUC.\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia:\n",
    "- [ROC-AUC](https://github.com/tunanottechnical/Jupyter-Workings/blob/master/Machine%20Learning%20in%20Mineral%20Exploration%20-%20Understanding%20Classification%20Evaluation%20Metrics.ipynb) <br>\n",
    "- [Métricas](https://www.kaggle.com/code/reighns/tutorial-on-machine-learning-metrics/notebook) <br>\n",
    "- [Google Crash Course](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall) <br>\n",
    " <br>\n",
    "\n",
    "\n",
    "## Material de Aprofundamento\n",
    "- [PR-Curve](https://www.kaggle.com/code/reighns/tutorial-on-machine-learning-metrics/notebook) <br>\n",
    "- [Adjusting the classification threshold](https://www.ritchieng.com/machine-learning-evaluate-classification-model/) <br>\n",
    "- [Gini](https://yassineelkhal.medium.com/confusion-matrix-auc-and-roc-curve-and-gini-clearly-explained-221788618eb2)\n",
    "- [Métricas](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
