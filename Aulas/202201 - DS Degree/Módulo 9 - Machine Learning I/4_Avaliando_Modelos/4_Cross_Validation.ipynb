{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula - Avaliando modelos\n",
    "\n",
    "Vamos ver outras estratégias para tentar escolher modelos por algum tipo de previsão do nosso erro de generalização.\n",
    "\n",
    "- 1) Holdout\n",
    "- 2) Leave One Out Cross Validation (LOOCV)\n",
    "- 3) Cross Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Estratégia \"Holdout set\": Conjuntos de treino, validação e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos, no aprendizado de máquina nós temos alguns dados (__conjunto de treino__), e depois fazemos um experimento com uma amostra de dados que nunca vimos (__conjunto de teste__) para saber o quão bem o modelo consegue generalizar.\n",
    "\n",
    "Assim, temos o erro dentro do conjunto de treino, $E_{in}$, e o erro de generalização, pra dados daquele tipo fora desse conjunto, $E_{out}$. \n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"images/treino_teste.png\" width=500>\n",
    "</div>\n",
    "\n",
    "O problema é que, __se usarmos o conjunto de teste de qualquer forma para aprendizado, o erro que obtivermos nele deixa de refletir o erro de generalização__. \n",
    "\n",
    "Por exemplo, se treinarmos 3 modelos, e compararmos eles usando o conjunto de teste, o erro no teste não reflete mais o $E_{out}$.\n",
    "\n",
    "Outro exemplo são certas transformações dos nossos dados. Imagina que pegamos nossos dados, \"normalizamos\" eles (ou seja, pegamos nossas features e transformamos elas de forma que tenham um range de 0 a 1), e então fazemos a divisão entre conjunto de treino e conjunto de teste. Nesse caso, você já usou o conjunto de teste para \"aprender\" algo (para normalizar, a gente usa o maior valor da feature na tabela). Logo, sua medida de $E_{out}$ não vale mais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que fazer então? Nós usamos o __conjunto de validação__ (ou _hold-out set_).\n",
    "<br><br>\n",
    "<div>\n",
    "    <img src=\"images/treino_validacao.png\" width=500>\n",
    "</div>\n",
    "\n",
    "Ao separar uma amostra (conjunto de validação), e usá-la apenas para seleção de modelos, nós assumimos que esse uso não afeta muito o erro. Então vamos dizer que o erro de validação, $E_{val}$, __aproxima de certa forma o erro de generalização__.\n",
    "\n",
    "<img src=\"images/cv.png\" width=500 text=\"https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/ch06/ch06.ipynb\">\n",
    "\n",
    "\n",
    "Isso foi o que fizemos nas últimas aulas.\n",
    "\n",
    "Após validar e escolher o modelo, nós queremos sempre seguir adiante com o melhor modelo possível. Assim, para melhorar o modelo, nós aumentamos o número de dados para treinar o modelo final.\n",
    "\n",
    "Então aí sim, nós juntamos treino, validação e teste em uma única base, e treinamos o modelo final. Entende-se que os erros do nosso algoritmo só tendem a diminuir, quando fazemos isso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Leave One Out Cross Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós usamos, até agora, a estratégia de \"hold-out set\" (ou de conjunto de validação) para podermos comparar modelos.\n",
    "\n",
    "Porém, ela tem algumas fraquezas. Especificamente, a gente precisa de dados suficientes no conjunto de validação para tentar aproximar melhor o erro de generalização. Mas isso faz com que tenhamos cada vez menos dados de treino, para treinar o melhor modelo possível!\n",
    "\n",
    "Será que teria alguma forma de garantirmos uma boa validação, mas ainda tendo o máximo possível de dados pra treino? \n",
    "\n",
    "A resposta é __sim__. Entra em cena o __Leave One Out Cross Validation (LOOCV)__.\n",
    "<br><br>\n",
    "<div>\n",
    "    <img src=\"images/LOOCV.png\" width=600>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Ele funciona assim:\n",
    "- Nós tiramos 1 ponto dos dados de treino\n",
    "- Treinamos o modelo nos outros N-1 pontos\n",
    "- Avaliamos o modelo naquele ponto que tiramos\n",
    "- Repete esse procedimento para _todos_ os pontos da base de treino \n",
    "\n",
    "Embora o Scikit-Learn tenha ferramentas para usarmos o LOOCV, raramente esse método é aplicado na prática. O motivo disso é que ele é __muito custoso computacionalmente__, e esse custo aumenta cada vez mais quanto mais dados de treino tivermos.\n",
    "\n",
    "Além disso, em termos de acurácia o LOO geralmente resulta em uma maior variância. Dado que os folds construídos são basicamente identicos uns aos outros (e idêntinco ao dataset original), não há diferença significativa entre os modelos criados em cada iteração.\n",
    "\n",
    "Nós não vamos testar esse método devido à esses motivos e vamos focar no seu primo mais útil: a validação cruzada.\n",
    "\n",
    "[Documentação do sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cross Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: Material de aulas do prof. Sandro Saorin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O __Cross Validation (CV)__ (ou validação cruzada, em português) é uma técnica muito utilizada para estimar o erro de generalização do modelo. Ele é semelhante ao LOOCV, mas invés de separarmos apenas 1 ponto de cada vez, nós separamos um __bloco de pontos__.\n",
    "\n",
    "Com ela podemos testar a capacidade de generalização de um modelo. A técnica faz divisões na base de dados de treino e teste e permite treinar e validar seus dados em diversos grupos distintos. Dessa forma, conseguimos mensurar a flexibilidade ou capacidade de generalização de um modelo antes mesmo da chegada de novos dados.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=600>\n",
    "\n",
    "Vamos discutir o passo a passo do que está acontecendo:\n",
    "- Como sempre, primeiro temos que garantir que a validação não aconteça usando a base de teste.\n",
    "- A gente separa a nossa base de treino em diversas partes (o mais comum são 3, 5 ou 10).\n",
    "- Cada parte vai ser usada 1 vez como base de validação, para um treino realizado nas outras partes. (Na figura, por exemplo, temos 5 rodadas, e em cada rodada um bloco diferente é usado como validação, enquanto os outros 4 são usados para treino).\n",
    "- Calculamos as métricas de avaliação em cada uma dessas rodadas, para a base de validação.\n",
    "- Por fim, temos como resultado o score médio para o nosso modelo (tirando a média das métricas para cada parte usada como validação), ou seja, o quão bom ele está generalizando.\n",
    "\n",
    "<br>\n",
    "\n",
    "No sklearn podemos criar esses _folds_ utilizando os médotos [__K-Fold__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) e [__Stratified K-Fold__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold). Eles irão retornar os indices dos arrays de dados de acordo com o número de partições escolhidas.\n",
    "\n",
    "A diferença entre amobos é semelhante ao que discutimos sobre usar ou não o parâmetro \"stratify\" da função \"train_test_split\". O __K-Fold__ faz uma quebra sem se preocupar com a distribuição das classes, enquanto o __Stratified K-Fold__ garante a mesma proporção em todos os _folds_.\n",
    "\n",
    "A gente pode usar o _stratified k-fold_ para quaisquer problemas que quisermos, embora o mais comum seja ele ser usado quando as nossas classes _target_ são muito __desbalanceadas__. Se uma das classes aparece muito menos que a outra, é possível que tenhamos uma quebra muito ruim. Em casos extremos, se uma classe aparece muito pouco, é possível que, sem a estratificação, ela sequer apareça em alguns _folds_.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Vamos ver como funciona a criação e uso dos folds na prática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3_ANgR1FTqXi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation Request:\n",
      "  This dataset is public available for research. The details are described in [Moro et al., 2011]. \n",
      "  Please include this citation if you plan to use this database:\n",
      "\n",
      "  [Moro et al., 2011] S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n",
      "  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, Portugal, October, 2011. EUROSIS.\n",
      "\n",
      "  Available at: [pdf] http://hdl.handle.net/1822/14838\n",
      "                [bib] http://www3.dsi.uminho.pt/pcortez/bib/2011-esm-1.txt\n",
      "\n",
      "1. Title: Bank Marketing\n",
      "\n",
      "2. Sources\n",
      "   Created by: Paulo Cortez (Univ. Minho) and Sérgio Moro (ISCTE-IUL) @ 2012\n",
      "   \n",
      "3. Past Usage:\n",
      "\n",
      "  The full dataset was described and analyzed in:\n",
      "\n",
      "  S. Moro, R. Laureano and P. Cortez. Using Data Mining for Bank Direct Marketing: An Application of the CRISP-DM Methodology. \n",
      "  In P. Novais et al. (Eds.), Proceedings of the European Simulation and Modelling Conference - ESM'2011, pp. 117-121, Guimarães, \n",
      "  Portugal, October, 2011. EUROSIS.\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   The data is related with direct marketing campaigns of a Portuguese banking institution. \n",
      "   The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, \n",
      "   in order to access if the product (bank term deposit) would be (or not) subscribed. \n",
      "\n",
      "   There are two datasets: \n",
      "      1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).\n",
      "      2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.\n",
      "   The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).\n",
      "\n",
      "   The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
      "\n",
      "5. Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)\n",
      "\n",
      "6. Number of Attributes: 16 + output attribute.\n",
      "\n",
      "7. Attribute information:\n",
      "\n",
      "   For more information, read [Moro et al., 2011].\n",
      "\n",
      "   Input variables:\n",
      "   # bank client data:\n",
      "   1 - age (numeric)\n",
      "   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
      "                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
      "   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
      "   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
      "   5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
      "   6 - balance: average yearly balance, in euros (numeric) \n",
      "   7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
      "   8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
      "   # related with the last contact of the current campaign:\n",
      "   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
      "  10 - day: last contact day of the month (numeric)\n",
      "  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
      "  12 - duration: last contact duration, in seconds (numeric)\n",
      "   # other attributes:\n",
      "  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
      "  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
      "  15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
      "  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
      "\n",
      "  Output variable (desired target):\n",
      "  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/bank-names.txt', 'r') as fp:\n",
    "    print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MVm7AWcyTqXn",
    "outputId": "7015e055-f46d-4eb6-9c0f-3ca62fbaba5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome Target  \n",
       "0  unknown    5   may       261         1     -1         0  unknown     no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown     no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown     no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown     no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown     no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o dataset e olhando para os nossos dados\n",
    "df = pd.read_csv('../data/bank-full.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  Target     45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Vamos dar uma olhada em como está os nossos dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dhofpm0GTqXx",
    "outputId": "aa2a0425-336d-4b23-eeb9-1586d09eb8f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     39922\n",
       "yes     5289\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a proporção da target\n",
    "df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FgRJMALrTqXz"
   },
   "outputs": [],
   "source": [
    "# Dropando a target e a duração da chamada das nossas features\n",
    "X = df.drop(columns=['Target', 'duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As nossas variáveis categóricas precisam ser transformadas em dados numéricos.\n",
    "Até agora, no máximo transformamos em um número de 0 a N.\n",
    "\n",
    "Contundo, geralmente essas variáveis não tem uma ordem. ('assalariado' é maior ou menor do que 'aposentado'?) Quando colocamos 0 a N, nós sem querer introduzimos essa ordem artificialmente.\n",
    "\n",
    "Assim, muitas vezes o ideal é quebrar aquela coluna em variáveis \"indicadoras\".\n",
    "\n",
    "Vão ser várias colunas, com valor 0 ou 1, sendo 0 quando não é aquele valor, e 1 quando é aquele valor. Chamamos isso de __One Hot Encoding__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0bB8gN8wTqX1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como era nosso dataframe original:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a      b\n",
       "0  1  0.450\n",
       "1  2  0.100\n",
       "2  1  0.230\n",
       "3  2  0.980\n",
       "4  1  0.100\n",
       "5  2  0.999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como ele fica após fazermos One Hot Encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a_1</th>\n",
       "      <th>a_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       b  a_1  a_2\n",
       "0  0.450    1    0\n",
       "1  0.100    0    1\n",
       "2  0.230    1    0\n",
       "3  0.980    0    1\n",
       "4  0.100    1    0\n",
       "5  0.999    0    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vamos ver um exemplo na prática.\n",
    "pontos = pd.DataFrame({'a':[1, 2, 1, 2, 1, 2],\n",
    "                       'b':[0.45, 0.1, 0.23, 0.98, 0.1, 0.999]})\n",
    "\n",
    "print(\"Como era nosso dataframe original:\")\n",
    "display(pontos)\n",
    "\n",
    "print(\"Como ele fica após fazermos One Hot Encoding:\")\n",
    "display(pd.get_dummies(pontos, prefix_sep='_', columns=['a']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sklearn também tem uma ferramenta para realizar o mesmo procedimento, que é uma classe chamada \"OneHotEncoding\", mas não usaremos ele nessa aula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo um get_dummies para colunar as nossas variáveis categóricas\n",
    "X_with_dummies = pd.get_dummies(X, prefix_sep = '_', drop_first=True, columns=['job', \n",
    "                                                                                'marital', \n",
    "                                                                                'education',\n",
    "                                                                                'default',\n",
    "                                                                                'housing',\n",
    "                                                                                'loan',\n",
    "                                                                                'contact',\n",
    "                                                                                'month',\n",
    "                                                                                'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9mvJfNGGTqX5",
    "outputId": "3c6abb1a-93a3-4b7b-bb8d-1adb25e485a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformando a target\n",
    "y_target = np.where(df['Target'] == 'yes', 1, 0)\n",
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0NKz6wUPTqX9"
   },
   "outputs": [],
   "source": [
    "#Separando em train e test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_dummies, \n",
    "                                                    y_target, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KD8yy_EQTqYC"
   },
   "outputs": [],
   "source": [
    "# Testando com o modelo DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instancia o modelo\n",
    "model = DecisionTreeClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "c3hDg7MgTqYF",
    "outputId": "902ec989-8c7d-417e-936e-ee50588e2041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa o StratifiedKFold do sklearn.model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Instancia a classe do StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos transformar o X de treino em array do numpy para facilitar manipulação\n",
    "X_train_arr = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CTDv-cL8TqYH",
    "outputId": "6ba68f48-cddf-4b79-9464-cede0c2e2abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Fold  1\n",
      "TRAIN: [    0     1     2 ... 31642 31645 31646] VALIDATION: [    4     7    12 ... 31638 31643 31644]\n",
      "Accuracy:  0.82\n",
      "Precison:  0.28\n",
      "Recal:     0.33\n",
      "F1-Score:  0.3\n",
      "============================================================================================\n",
      "Fold  2\n",
      "TRAIN: [    1     3     4 ... 31643 31644 31646] VALIDATION: [    0     2     5 ... 31640 31641 31645]\n",
      "Accuracy:  0.83\n",
      "Precison:  0.29\n",
      "Recal:     0.35\n",
      "F1-Score:  0.32\n",
      "============================================================================================\n",
      "Fold  3\n",
      "TRAIN: [    0     2     4 ... 31643 31644 31645] VALIDATION: [    1     3     9 ... 31639 31642 31646]\n",
      "Accuracy:  0.83\n",
      "Precison:  0.27\n",
      "Recal:     0.28\n",
      "F1-Score:  0.28\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Neste caso, teremos que montar manualmente cada iteração.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "list_accuracy = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "list_f1_score = []\n",
    "\n",
    "i = 1\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    \n",
    "    print(\"============================================================================================\")\n",
    "    print(\"Fold \", i)\n",
    "    print(\"TRAIN:\", train_index, \"VALIDATION:\", val_index)\n",
    "    \n",
    "    # Pegando o X e o y de treino e de validação para aquela iteração\n",
    "    KFold_X_train, KFold_X_val = X_train_arr[train_index], X_train_arr[val_index]\n",
    "    KFold_y_train, KFold_y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Treinando o modelo da iteração\n",
    "    model.fit(KFold_X_train, KFold_y_train)\n",
    "    \n",
    "    # Fazendo as previsões no \"fold\" de validação\n",
    "    y_pred = model.predict(KFold_X_val)\n",
    "    \n",
    "    #Calcula as métricas\n",
    "    acc = accuracy_score(KFold_y_val, y_pred)\n",
    "    prec = precision_score(KFold_y_val, y_pred)\n",
    "    recall = recall_score(KFold_y_val, y_pred)\n",
    "    f1 = f1_score(KFold_y_val, y_pred)\n",
    "    \n",
    "    # Mostrando em tela as métricas\n",
    "    print(\"Accuracy: \", round(acc, 2))\n",
    "    print(\"Precison: \", round(prec, 2))\n",
    "    print(\"Recal:    \", round(recall,2))\n",
    "    print(\"F1-Score: \", round(f1, 2))\n",
    "    \n",
    "    # Salvando as métricas na lista\n",
    "    list_accuracy.append(acc)\n",
    "    list_precision.append(prec)\n",
    "    list_recall.append(recall)\n",
    "    list_f1_score.append(f1)\n",
    "    i += 1\n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_val_score: facilitando nossa vida\n",
    "\n",
    "O Scikit-Learn já possui métodos implementados que calculam os score dentro dos folds e um deles é o  [__cross_val_score__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html): Precisamos apenas informar qual a quantidade de folds (cv) e qual métrica queremos avaliar (score). A saída do método é a média para cada partição considerando a métrica escolhida.\n",
    "\n",
    "Se quisermos avaliar mais de uma métrica dentro dos mesmos folds ou se quisermos o tempo necessário para o fit podemos utilizar o método [__cross_validate__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "\n",
    "Se o parâmetro __cv__ for um inteiro ou None e o estimador for de classificação (binário ou multiclass), o StratifiedKFold será usado, caso contrário o KFold é o selecionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "W67qn7hpTqYD",
    "outputId": "6841bf8d-cad3-4061-8c35-c0cec4070192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82369668, 0.83191153, 0.83156897, 0.82730289, 0.8277769 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando o Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia média de todos os folds é 0.83 com um desvio padrão de 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"A acurácia média de todos os folds é %0.2f com um desvio padrão de %0.3f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- fit_time:\n",
      "-- [0.14157557 0.13328838 0.1261704  0.13502955 0.13005805]\n",
      "-- 0.13322439193725585 +- 0.005153436336664123\n",
      "\n",
      "- score_time:\n",
      "-- [0.00476956 0.00502563 0.0047617  0.00493693 0.00513077]\n",
      "-- 0.004924917221069336 +- 0.00014383108192928104\n",
      "\n",
      "- test_accuracy:\n",
      "-- [0.82369668 0.83191153 0.83156897 0.82730289 0.8277769 ]\n",
      "-- 0.8284513949055189 +- 0.00303555954853931\n",
      "\n",
      "- test_precision:\n",
      "-- [0.27863046 0.30135301 0.29262087 0.2978236  0.28015075]\n",
      "-- 0.29011573793604795 +- 0.009199735014163364\n",
      "\n",
      "- test_recall:\n",
      "-- [0.31848853 0.33063428 0.31081081 0.35135135 0.30135135]\n",
      "-- 0.32252726410621146 +- 0.01731217848681251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "nome_metricas = ['accuracy', 'precision', 'recall']\n",
    "metricas = cross_validate(model, X_train, y_train, cv=5, scoring=nome_metricas)\n",
    "\n",
    "for met in metricas:\n",
    "    print(f\"- {met}:\")\n",
    "    print(f\"-- {metricas[met]}\")\n",
    "    print(f\"-- {np.mean(metricas[met])} +- {np.std(metricas[met])}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.14157557, 0.13328838, 0.1261704 , 0.13502955, 0.13005805]),\n",
       " 'score_time': array([0.00476956, 0.00502563, 0.0047617 , 0.00493693, 0.00513077]),\n",
       " 'test_accuracy': array([0.82369668, 0.83191153, 0.83156897, 0.82730289, 0.8277769 ]),\n",
       " 'test_precision': array([0.27863046, 0.30135301, 0.29262087, 0.2978236 , 0.28015075]),\n",
       " 'test_recall': array([0.31848853, 0.33063428, 0.31081081, 0.35135135, 0.30135135])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "Faça a validação cruzada para três métricas distintas no dataset bank-full e compare o KNN com a Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia e Aprofundamento\n",
    "- [Métricas](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "- [Time Series Split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit)\n",
    "- [Sklearn Cross validation iterators](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ca4efd453f89b69dfc80cbb5ef222b3d24fc169b1efe916ea8f932329929361"
  },
  "kernelspec": {
   "display_name": "Python (DataScience)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
